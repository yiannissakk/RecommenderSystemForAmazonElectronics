{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)\n",
    "\n",
    "This Notebook is a slightly altered homework for CS591: Data Mining Class at Boston University, taught by Professor George Kollios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System for Amazon Electronics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will be working with the Amazon dataset. The part of it that we will be using, can be found in the same repository as this notebook. We will build a recommender system to make predictions related to reviews of Electronics products on Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train.json** 1,000,000 reviews to be used for training. It is not necessary to use all reviews for training if doing so proves too computationally intensive. The fields in this file are:\n",
    "\n",
    "* **reviewerID** The ID of the reviewer. This is a hashed user identifier from Amazon.\n",
    "\n",
    "* **asin** The ID of the item. This is a hashed product identifier from Amazon.\n",
    "\n",
    "* **overall** The rating of reviewer gave the item.\n",
    "\n",
    "* **helpful** The helpfulness votes for the review. This has 2 subfields, 'nHelpful' and 'outOf'. The latter is the total number of votes this review received. The former is the number of those that considered the review to be helpful.\n",
    "\n",
    "* **reviewText** The text of the review.\n",
    "\n",
    "* **summary** The summary of the review.\n",
    "\n",
    "* **unixReviewTime** The time of the review in seconds since 1970."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**meta.json** Contains metadata of the items:\n",
    "\n",
    "* **asin** The ID of the item.\n",
    "\n",
    "* **categories** The category labels of the item being reviewed.\n",
    "\n",
    "* **price** The price of the item.\n",
    "\n",
    "* **brand** The brand of the item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pairs_Rating.txt** The pairs (reviewerID and asin) on which you are to predict ratings.\n",
    "\n",
    "**pairs_Helpful.txt** The pairs on which you are to predict helpfulness votes. A third column in this file is the total number of votes from which you should predict how many were helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**helpful.json** The review data associated with the helpfulness prediction test set. The 'nHelpful' field has been removed from this data since that is the value you need to predict above. This data will only be of use for the helpfulness prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Rating prediction** Predict people's star ratings as accurately as possible for those (reviewerID, asin) pairs in 'pairs_Rating.txt'. Accuracy will be measured in terms of the root mean-squared error (RMSE).\n",
    "\n",
    "**2. Helpfulness prediction** Predict whether a user's review of an item will be considered helpful. The file 'pairs_Helpful.txt' contains (reviewerID, asin) pairs with a third column containing the number of votes the user's review of the item received. We must predict how many of them were helpful. Accuracy will be measured in terms of the total absolute error, i.e. the difference |nHelpful - prediction|, where 'nHelpful' is the number of helpful votes the review actually received, and 'prediction' is our prediction of this quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track of our results a competition was created in Kaggle to keep track of the classes results. The leaderboard will show your results on half of the test data, but your ultimate score will depend on your predictions across the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy import linalg\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def readJson(f):\n",
    "    for l in open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The following attempts are the ones that were the most successful ones. I tried using stochastic gradient descent as well as other techniques which were not as succesful as the ones I am going to present here. In both contests, I scored in the top thirds of the leaderboard (class of 60 people)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each user in train.json I computed the amount of times he purchased any item, putting it in a dictionary (userdensity). For each item I computed the amount of times it was purchased, putting it also in a dictionary (itemdensity). Then for each of the users and items I computed the average score they either gave or got depending if they were a user or an item. These values were also  put in dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, once I got in the file with the missing ratings, I had a user and an item. If that user was in userdensity and item was in itemdensity, I got the number of purchases for the user (unum) and the item (inum). I also got the average ratings for the user and the item. To find the predicted rating I used the equation:\n",
    "\n",
    "$$(\\dfrac{unum}{(unum+inum)})*user\\_average+(\\dfrac{inum}{(unum+inum)})*item\\_average$$\n",
    "\n",
    "which gives a weighted average of the sum of the averages of the item and the user. \n",
    "\n",
    "Moreover, I realized if the above equation gave me a value larger than five or less than one, it would be more efficient if I changed them to 5 and 1 respectively. \n",
    "\n",
    "For the tuples that were not in userdensity and itemdensity I checked them independently and returned just their item's or user's average, depending on which was present. \n",
    "\n",
    "Finally due to the inconsistence of such datasets, factoring in the global average on every result made our results better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE of the method was 1.39786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "\n",
    "itemRatings = defaultdict(dict)\n",
    "for l in readJson('amazon_reviews_Electronics/train.json'):\n",
    "    userId,itemId,rating = l['reviewerID'],l['asin'],l['overall']\n",
    "    itemRatings[itemId][userId] = rating\n",
    "    \n",
    "allRatings = []\n",
    "userRatings = defaultdict(dict)\n",
    "for l in readJson('amazon_reviews_Electronics/train.json'):\n",
    "    userId,itemId,rating = l['reviewerID'],l['asin'],l['overall']\n",
    "    allRatings.append(rating)\n",
    "    userRatings[userId][itemId] = rating  \n",
    "    \n",
    "globalAverage = (sum(allRatings) / len(allRatings)) \n",
    "\n",
    "userAverage = {}\n",
    "for u in userRatings.keys():\n",
    "    userAverage[u] = (sum(userRatings[u].values()) / len(userRatings[u]))\n",
    "    \n",
    "itemAverage = {}\n",
    "for i in itemRatings.keys():\n",
    "    if len(itemRatings[i]) == 0:\n",
    "        itemAverage[i] = globalAverage\n",
    "    else:\n",
    "        itemAverage[i] = (sum(itemRatings[i].values()) / len(itemRatings[i]))\n",
    "\n",
    "    \n",
    "userdensity = {}\n",
    "for user in userRatings.keys():\n",
    "    userdensity[user] = len(userRatings[user].keys())\n",
    "    \n",
    "itemdensity = {}\n",
    "for item in itemRatings.keys():\n",
    "    itemdensity[item] = len(itemRatings[item].keys())\n",
    "\n",
    "for l in open(\"amazon_reviews_Electronics/pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    #play with the biases\n",
    "    if i in itemAverage:\n",
    "        this_item_average = itemAverage[i]\n",
    "    else:\n",
    "        this_item_average = globalAverage\n",
    "    if u in userAverage:\n",
    "        this_user_average = userAverage[u]\n",
    "    else:\n",
    "        this_user_average = globalAverage\n",
    "    this_item_bias = this_item_average - globalAverage\n",
    "    this_user_bias = this_user_average - globalAverage\n",
    "    \n",
    "    dodal = {}#takes into account all others that rated i, could add it to value as another factor\n",
    "    dod = []\n",
    "    b =0\n",
    "    for item_user in itemRatings[i].keys():\n",
    "        total_score = [0.0,0.0]\n",
    "        common_items = list(set(userRatings[u].keys()).intersection(userRatings[item_user].keys()))\n",
    "        if common_items != []: \n",
    "            for common_item in common_items:\n",
    "                score = float(itemRatings[common_item][u])-float(itemRatings[common_item][item_user])\n",
    "                total_score[0] = total_score[0] + score \n",
    "                total_score[1] = total_score[1] + 1\n",
    "                valueq = total_score[0]/total_score[1]\n",
    "                dod.append(valueq)\n",
    "            #valueq = total_score[0]/total_score[1]\n",
    "            #dodal[item_user] = userRatings[item_user][i]+valueq\n",
    "        else: #no common items\n",
    "            dod.append(userRatings[item_user][i])\n",
    "            #dodal[item_user] = userRatings[item_user][i]\n",
    "        b = b + 1\n",
    "    if len(dod) == 0.0:\n",
    "    #if len(dodal) == 0.0: #no one has reviewed item\n",
    "        val= this_user_average\n",
    "    else:\n",
    "        val = sum(dod)/len(dod)\n",
    "        #val = sum(dodal.values())/len(dodal.keys())  \n",
    "\n",
    "    if u in userdensity and i in itemdensity:\n",
    "        unum=userdensity[u]\n",
    "        inum=itemdensity[i]\n",
    "        #change\n",
    "        total = float(unum +inum)\n",
    "        #here\n",
    "        value = (unum/total)*this_user_average+(inum/total)*this_item_average\n",
    "        #print (value)\n",
    "        if value>5:\n",
    "            value = 5\n",
    "        if value<0:\n",
    "            value = 0\n",
    "        predictions.write(u + '-' + i + ',' + str(value*0.68+0.32*globalAverage) + '\\n')\n",
    "    elif i in itemRatings:\n",
    "        #here\n",
    "        predictions.write(u + '-' + i + ',' + str((this_item_average)*0.68+0.32*globalAverage) + '\\n')\n",
    "    elif u in userRatings:\n",
    "        #and here\n",
    "        predictions.write(u + '-' + i + ',' + str((this_user_average)*0.68+0.32*globalAverage) + '\\n')\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + ',' + str(globalAverage) + '\\n')\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each, row in train.json has a nhelpful and an outOf column. Thus, for all possible outOf values I computed the average nhelpful/outOf rate and put them in a dictionary. Now when I was asked to compute the amount of nhelpful of a review in helpful.json I just went back to the outOf dictionary I created, got the value for the respective outOf value and then multiplied it by outOf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute error of that method was 61667.70004 which translates to almost a 40% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allHelpful = []\n",
    "userHelpful = defaultdict(list)\n",
    "itemHelpful = defaultdict(list)\n",
    "userHelpfuld = defaultdict(dict)\n",
    "itemHelpfuld = defaultdict(dict)\n",
    "textu = defaultdict(dict)\n",
    "texti = defaultdict(dict)\n",
    "score = defaultdict(dict)\n",
    "userOutOfs = defaultdict(dict)\n",
    "\n",
    "for l in readJson('amazon_reviews_Electronics/train.json'):\n",
    "    user,item = l['reviewerID'],l['asin']\n",
    "    allHelpful.append(l['helpful'])\n",
    "    textu[user][item] = len(l['reviewText'])\n",
    "    score[user][item] = l[\"overall\"]\n",
    "    a = l[\"helpful\"]\n",
    "    userOutOfs[user][item] = a['outOf']\n",
    "    userHelpfuld[user][item] = float(a['nHelpful'])/float(a['outOf'])\n",
    "\n",
    "\n",
    "a=[]    \n",
    "rt=0\n",
    "mama = defaultdict(int)\n",
    "mamnum = defaultdict(int)\n",
    "\n",
    "tlen = defaultdict(dict)\n",
    "rt = 0\n",
    "for u in userHelpfuld:\n",
    "    for i in userHelpfuld[u]:\n",
    "        mama[str(userOutOfs[u][i])] = mama[str(userOutOfs[u][i])] + userHelpfuld[u][i]\n",
    "        mamnum[str(userOutOfs[u][i])] = mamnum[str(userOutOfs[u][i])]+1\n",
    "        if userOutOfs[u][i]==2 and textu[u][i]<100:\n",
    "            rt = rt+1\n",
    "            tlen[u][i]=userHelpfuld[u][i]\n",
    "            \n",
    "\n",
    "tlensum=0\n",
    "for gh in tlen:\n",
    "    tlensum=tlensum+sum(tlen[gh].values())\n",
    "           \n",
    "lis=defaultdict(dict)            \n",
    "for mam in mama:\n",
    "    lis[mam]= mama[mam]/mamnum[mam]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text = defaultdict(dict)\n",
    "userOutOf = defaultdict(dict)\n",
    "for l in readJson(\"amazon_reviews_Electronics/helpful.json\"):\n",
    "    use,ite = l['reviewerID'],l['asin']\n",
    "    userOutOf[use][ite] = l['outOf']\n",
    "    text[use][ite] = len(l['reviewText'])\n",
    "    \n",
    "predictions = open(\"predictions_Helpful.txt\", 'w')\n",
    "for l in open(\"amazon_reviews_Electronics/pairs_Helpful.txt\"):\n",
    "    boo = False \n",
    "    if l.startswith(\"reviewerID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i,outOf = l.strip().split('-')\n",
    "    outOf = int(outOf)\n",
    "    o = outOf\n",
    "    while boo == False:\n",
    "        if o==1:\n",
    "            boo = True\n",
    "            predictions.write(u + '-' + i + '-' + str(o) + ',' + str(1) + '\\n')\n",
    "        elif str(outOf) in lis:\n",
    "            boo = True\n",
    "            predictions.write(u + '-' + i + '-' + str(o) + ',' + str(outOf*lis[str(outOf)]) + '\\n')\n",
    "        outOf = outOf-1    \n",
    "predictions.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image-based recommendations on styles and substitutes** J. McAuley, C. Targett, J. Shi, A. van den Hengel *SIGIR*, 2015\n",
    "\n",
    "**Inferring networks of substitutable and complementary products** J. McAuley, R. Pandey, J. Leskovec *Knowledge Discovery and Data Mining*, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for setting the style of the notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../theme/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
